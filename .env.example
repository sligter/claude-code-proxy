# .env.example

# === BIG MODEL CONFIGURATION ===
# Used for complex requests (Claude Sonnet, Opus)
BIG_MODEL_PROVIDER="openai"
BIG_MODEL_API_KEY="sk-your-openai-api-key-here"
BIG_MODEL_BASE_URL="https://api.openai.com/v1"
BIG_MODEL_NAME="gpt-4o"
# Required for Azure OpenAI, e.g., "2024-02-01"
# BIG_MODEL_AZURE_API_VERSION="" 

# === SMALL MODEL CONFIGURATION ===
# Used for fast requests (Claude Haiku)
SMALL_MODEL_PROVIDER="openai"
SMALL_MODEL_API_KEY="sk-your-openai-api-key-here"
SMALL_MODEL_BASE_URL="https://api.openai.com/v1"
SMALL_MODEL_NAME="gpt-4o-mini"
# Required for Azure OpenAI
# SMALL_MODEL_AZURE_API_VERSION=""

# === SERVER SETTINGS ===
HOST="0.0.0.0"
PORT="8082"
LOG_LEVEL="INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL

# === PERFORMANCE SETTINGS ===
MAX_TOKENS_LIMIT="8196"
MIN_TOKENS_LIMIT="100"
REQUEST_TIMEOUT="90"
MAX_RETRIES="2"

# === PROVIDER EXAMPLES ===

# --- Example 1: Using OpenAI for both models (default setup) ---
# BIG_MODEL_API_KEY="sk-your-openai-key"
# SMALL_MODEL_API_KEY="sk-your-openai-key" # Can be the same key

# --- Example 2: Azure OpenAI for Big model, OpenAI for Small model ---
# BIG_MODEL_PROVIDER="azure"
# BIG_MODEL_API_KEY="your-azure-key"
# BIG_MODEL_BASE_URL="https://your-resource.openai.azure.com/"
# BIG_MODEL_NAME="gpt-4"
# BIG_MODEL_AZURE_API_VERSION="2024-02-01"
#
# SMALL_MODEL_PROVIDER="openai"
# SMALL_MODEL_API_KEY="sk-your-openai-key"
# SMALL_MODEL_NAME="gpt-4o-mini"

# --- Example 3: Local models (Ollama) for both ---
# BIG_MODEL_PROVIDER="ollama"
# BIG_MODEL_API_KEY="dummy-key"
# BIG_MODEL_BASE_URL="http://localhost:11434/v1"
# BIG_MODEL_NAME="llama3.1:70b"
#
# SMALL_MODEL_PROVIDER="ollama"
# SMALL_MODEL_API_KEY="dummy-key"
# SMALL_MODEL_BASE_URL="http://localhost:11434/v1"
# SMALL_MODEL_NAME="llama3.1:8b"
